{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f187975a-9b74-4905-9c61-87ae1f05ee80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports \n",
    "import cv2\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6dfca28-fb5d-48ec-a7b3-01c68caf3e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "with open('../../../settings.json') as f:\n",
    "    json_s = f.read()\n",
    "    analysis_info = json.loads(json_s)\n",
    "\n",
    "# Define directories \n",
    "home_dir = '/Users/uriel/disks/meso_shared'\n",
    "main_dir = '{}/RetinoMaps'.format(home_dir)\n",
    "\n",
    "\n",
    "tasks = ['pRF', 'PurLoc', 'SacLoc']\n",
    "task = tasks[0]\n",
    "\n",
    "stim_video_fn = '{}/derivatives/vdm/{}_vid.mp4'.format(main_dir,task)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e9cce6-501e-4641-90a4-6e3cbc485415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# open video\n",
    "cap = cv2.VideoCapture(stim_video_fn)\n",
    "\n",
    "# get video settings\n",
    "vid_width, vid_height = cap.get(3), cap.get(4)\n",
    "vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "vid_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "# set VDM settings\n",
    "TR = analysis_info['TR']\n",
    "vdm_width = analysis_info['vdm_size_pix_eyes_mvt'][0] \n",
    "vdm_height = analysis_info['vdm_size_pix_eyes_mvt'][1]\n",
    "vdm_frames_sampled = vid_fps * TR\n",
    "vdm_frames = vid_frames / vdm_frames_sampled\n",
    "vdm_mat = np.zeros((vdm_width, vdm_height, int(vdm_frames)))\n",
    "\n",
    "# define top and bottom part as 16/9 screen experiment and VDM should be a square\n",
    "height_to_add = (vid_width - vid_height) / 2 \n",
    "add_mat =  np.zeros((int(height_to_add),int(vid_width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83de052b-a2f7-42ac-8d17-cc70ceca9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defind outputs fn \n",
    "vdm_video_fn = '{}/derivatives/vdm/vdm_{}_{}_{}.mp4'.format(main_dir, task, vdm_width, vdm_height)\n",
    "vdm_numpy_fn = '{}/derivatives/vdm/vdm_{}_{}_{}.npy'.format(main_dir, task, vdm_width, vdm_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19f43b96-a62e-449c-a6ed-07249d72b7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide the central fixation point\n",
    "center_x= int(vid_width / 2)\n",
    "center_y = int(vid_height / 2)\n",
    "radius = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe6d12f-f415-461f-8fd3-100fcc2482db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create VDM matrix\n",
    "vid_idx, vdm_idx = 0, 0\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    # read video frames\n",
    "    ret, vid_frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # process sampled frames\n",
    "    if np.mod(vid_idx, int(vdm_frames_sampled)) == 0:\n",
    "\n",
    "        # convert frame to grayscale\n",
    "        gray_mat = cv2.cvtColor(vid_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # convert to binary\n",
    "        binary_mat = (gray_mat > 5).astype(np.uint8)\n",
    "    \n",
    "        # add top and bottom blank    \n",
    "        binary_reshape_mat = np.concatenate((add_mat,binary_mat,add_mat), axis=0)\n",
    "        \n",
    "        # resize to create VDM\n",
    "        binary_reshape_resize_mat = cv2.resize(binary_reshape_mat, dsize=(vdm_width, vdm_height),\n",
    "                                               interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # fill VDM matrix\n",
    "        vdm_mat[...,vdm_idx] = binary_reshape_resize_mat\n",
    "        vdm_idx += 1\n",
    "\n",
    "\n",
    "    vid_idx += 1\n",
    "    \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bc027be-a73b-49a1-bc92-976083b2d79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save VDM as numpy matrix\n",
    "np.save(vdm_numpy_fn, vdm_mat)\n",
    "\n",
    "# save VDM as video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(vdm_video_fn, fourcc, 1/TR, (vdm_width, vdm_height), False)\n",
    "[out.write(np.uint8(frame*255)) for frame in np.split(vdm_mat, vdm_frames, axis=2)]\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
