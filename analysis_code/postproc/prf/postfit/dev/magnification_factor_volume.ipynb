{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca4ff21-660f-478e-800e-0245edb403cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computation of magnification factor using pycortex\n",
    "__To do :__\n",
    "- [x] fix problem with smaller radius\n",
    "- [x] compute point image\n",
    "- [x] exclude vertex not in roi\n",
    "- [x] plot data across multiple visual areas\n",
    "- [x] check if values correspond to Dumoulin with different radius around vertex\n",
    "- [x] plot data on flatmaps\n",
    "- [x] save data as nii.gz\n",
    "- [ ] do it in python code with loo analysis too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a2441-575e-41fa-91e8-55516e20f148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stop warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# General imports\n",
    "import cortex\n",
    "import importlib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"{}/../../../utils\".format(os.getcwd()))\n",
    "from pycortex_utils import draw_cortex, set_pycortex_config_file\n",
    "import nibabel as nb\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define analysis parameters\n",
    "with open('../../../settings.json') as f:\n",
    "    json_s = f.read()\n",
    "    analysis_info = json.loads(json_s)\n",
    "xfm_name = analysis_info[\"xfm_name\"]\n",
    "task = analysis_info[\"task\"]\n",
    "rois = analysis_info[\"rois\"]\n",
    "\n",
    "# debug\n",
    "rois = ['V1']\n",
    "\n",
    "# Inputs\n",
    "main_dir = '/home/mszinte/disks/meso_S/data/'\n",
    "project_dir = 'amblyo_prf'\n",
    "subject = 'sub-06'\n",
    "\n",
    "# set folders\n",
    "cortex_dir = \"{}/{}/derivatives/pp_data/cortex\".format(main_dir, project_dir)\n",
    "fit_dir = \"{}/{}/derivatives/pp_data/{}/prf/fit\".format(main_dir, project_dir, subject)\n",
    "deriv_avg_fn = \"{}/{}_task-{}_fmriprep_dct_bold_avg_prf-deriv.nii.gz\".format(fit_dir, subject, task)\n",
    "deriv_avg_loo_fn = \"{}/{}_task-{}_fmriprep_dct_bold_loo_avg_prf-deriv.nii.gz\".format(fit_dir, subject, task)\n",
    "deriv_fns = [deriv_avg_fn,deriv_avg_loo_fn]\n",
    "deriv_fn_labels = ['avg','loo_avg']\n",
    "\n",
    "# Set pycortex db and colormaps\n",
    "set_pycortex_config_file(cortex_dir)\n",
    "importlib.reload(cortex)\n",
    "\n",
    "# Define settings\n",
    "vert_dist_th = 2   # distance of vertex to include in mm\n",
    "\n",
    "# get surfaces for each hemisphere\n",
    "surfs = [cortex.polyutils.Surface(*d) for d in cortex.db.get_surf(subject, \"flat\")]\n",
    "surf_lh, surf_rh = surfs[0], surfs[1]\n",
    "\n",
    "# get the vertices number per hemisphere\n",
    "lh_vert_num, rh_vert_num = surf_lh.pts.shape[0], surf_rh.pts.shape[0]\n",
    "vert_num = lh_vert_num + rh_vert_num\n",
    "\n",
    "# get a dicst with the surface vertices contained in each ROI\n",
    "roi_verts_dict = cortex.utils.get_roi_verts(subject, mask=False)\n",
    "\n",
    "# mapper from voxels to vertices\n",
    "mapper = cortex.get_mapper(subject, xfm_name, 'line_nearest', recache=True)\n",
    "\n",
    "# Load params\n",
    "deriv_fn = deriv_fns[0]\n",
    "deriv_img = nb.load(deriv_fn)\n",
    "deriv_mat = deriv_img.get_fdata()\n",
    "\n",
    "# Maps settings\n",
    "params_num = 10\n",
    "rsq_idx, rsq_loo_idx, ecc_idx, polar_real_idx, polar_imag_idx , size_idx, \\\n",
    "    amp_idx, baseline_idx, x_idx, y_idx = 0,1,2,3,4,5,6,7,8,9\n",
    "\n",
    "# parameters in vertices\n",
    "vert_rsq_data = mapper(cortex.Volume(deriv_mat[...,rsq_idx].T, subject, xfm_name)).data\n",
    "vert_x_data = mapper(cortex.Volume(deriv_mat[...,x_idx].T, subject, xfm_name)).data\n",
    "vert_y_data = mapper(cortex.Volume(deriv_mat[...,y_idx].T, subject, xfm_name)).data\n",
    "vert_size_data = mapper(cortex.Volume(deriv_mat[...,size_idx].T, subject, xfm_name)).data\n",
    "vert_ecc_data = mapper(cortex.Volume(deriv_mat[...,ecc_idx].T, subject, xfm_name)).data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363919d7-14d7-43c1-8bdd-710da5b9a52f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Adaptation of Benson work : \n",
    "https://github.com/noahbenson/cortical-magnification-tutorial/blob/master/work/tutorial.ipynb\n",
    "\n",
    "## Moving Ring\n",
    "When cortical magnification is reported, it is often reported as a function of the degrees of eccentricity, e.g., Horton and Hoyt, 1991. This is because by far the biggest change in cortical magnification across the visual field covaries with eccentricity.\n",
    "\n",
    "To calculate the cortical magnification in terms of an eccentricity\n",
    ", a straightforward way is pick some ring of the visual field from eccentricity to eccentricity and to count up the total surface area of all the vertices in V1 (or another visual area) that have pRF centers inside the ring, then to divide that area by the area of the ring. Using scipy's spatial hashes, we can do this efficiently for any query; we can even return quantile data efficiently, as in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164d747-6f21-43e3-997c-5f27a19ee394",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_ecc = 1\n",
    "max_ecc = 15\n",
    "steps = 250\n",
    "ring_rads = np.linspace(min_ecc, max_ecc, backwardss)\n",
    "cmf = np.zeros((steps,3))\n",
    "roi = 'V1'\n",
    "roi_idx = np.zeros(vert_num)\n",
    "roi_idx[roi_verts_dict[roi]] = 1\n",
    "hemi_idx = np.zeros(vert_num)*np.nan\n",
    "hemi_idx[np.arange(0,lh_vert_num)] = 1 # rh\n",
    "hemi_idx[np.arange(lh_vert_num,vert_num)] = 2 #lh\n",
    "\n",
    "with tqdm(total=steps) as pbar:\n",
    "    for ring_num, ring_rad in enumerate(ring_rads):\n",
    "\n",
    "        # compute indices\n",
    "        eccs_not_null_idx = vert_ecc_data!=0\n",
    "        eccs_ring_idx = vert_ecc_data<=ring_rad\n",
    "        eccs_not_null_ring_roi_lh_idx = (eccs_not_null_idx==1) & (eccs_ring_idx==1) & (roi_idx==1) & (hemi_idx==1)\n",
    "        eccs_not_null_ring_roi_rh_idx = (eccs_not_null_idx==1) & (eccs_ring_idx==1) & (roi_idx==1) & (hemi_idx==2)\n",
    "        \n",
    "        # left hemisphere\n",
    "        if np.sum(eccs_not_null_ring_roi_lh_idx==True) > 0:\n",
    "            eccs_lh = vert_ecc_data[eccs_not_null_ring_roi_lh_idx]\n",
    "            visual_area_lh = np.pi / 2 * (np.max(eccs_lh, axis=0)**2 - np.min(eccs_lh, axis=0)**2)\n",
    "            surf_area_lh = np.sum(surf_lh.create_subsurface(\n",
    "                vertex_mask=eccs_not_null_ring_roi_lh_idx[:lh_vert_num]).face_areas)\n",
    "        else:\n",
    "            visual_area_lh = np.nan\n",
    "            surf_area_lh = np.nan\n",
    "        \n",
    "        # right hemisphere\n",
    "        if np.sum(eccs_not_null_ring_roi_rh_idx==True) > 0:\n",
    "            eccs_rh = vert_ecc_data[eccs_not_null_ring_roi_rh_idx]\n",
    "            visual_area_rh = np.pi / 2 * (np.max(eccs_rh, axis=0)**2 - np.min(eccs_rh, axis=0)**2)\n",
    "            surf_area_rh = np.sum(surf_rh.create_subsurface(\n",
    "                vertex_mask=eccs_not_null_ring_roi_rh_idx[lh_vert_num:]).face_areas)\n",
    "        else:\n",
    "            visual_area_rh = np.nan\n",
    "            surf_area_rh = np.nan\n",
    "            \n",
    "        # compute sum and cmf\n",
    "        visual_area = visual_area_lh + visual_area_rh\n",
    "        surf_area = surf_area_lh + surf_area_rh\n",
    "        cmf[ring_num] = (surf_area_lh / visual_area_lh, surf_area_rh / visual_area_rh, surf_area / visual_area)\n",
    "        \n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make the figure:\n",
    "(fig, ax) = plt.subplots(1,1, figsize=(5,5), dpi=100)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "x = ring_rads\n",
    "ax.plot(x, (17.3 / (0.75 + x))**2, 'k-', lw=1, label='Horton & Hoyt (1991)')\n",
    "ax.plot(x, cmf[:,0], 'b--', lw=1, label='{} LH'.format(roi))\n",
    "ax.plot(x, cmf[:,1], 'r--', lw=1, label='{} RH'.format(roi))\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticks([0.75, 1.5, 3, 6, 12])\n",
    "ax.set_xticklabels([0.75, 1.5, 3, 6, 12])\n",
    "ax.set_yticks([2,8,32,128])\n",
    "ax.set_yticklabels([2,8,32,128])\n",
    "ax.set_xlabel('Eccentricity [deg]')\n",
    "ax.set_ylabel(r'Cortical Mag. [mm$^2$/deg$^2$]')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed851be3-5ca6-4f7e-8211-468da2c38f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Harvey, B. M. & Dumoulin, S. O.**  \n",
    "#### The relationship between cortical magnification factor and population receptive field size in human visual cortex: constancies in cortical architecture. \n",
    "#### _The Journal of Neuroscience_ 31, 13604–13612 (2011).\n",
    "  \n",
    "_We determined the CMF for every voxel on the gray–white matter\n",
    "border independently. All analysis of pRF, CMF, and point image was\n",
    "therefore restricted to voxels on the gray–white matter border. Gray\n",
    "matter thickness was ignored, effectively treating the gray–white matter\n",
    "border as the cortical surface. At each cortical location, we computed the\n",
    "distance (in millimeters) to neighboring locations along the cortical sur-\n",
    "face. To compute the CMF, this cortical distance was divided by the\n",
    "change in preferred pRF location (degrees of visual angle) of the same\n",
    "cortical locations. Neighboring voxels with poor pRF model fits (vari-\n",
    "ance explained \u000630%) were removed from this computation, as were\n",
    "voxels outside the ROI. The population point image was computed by\n",
    "multiplying the CMF and pRF size estimates for each cortical location.\n",
    "This technique estimates the CMF and point image for each individual\n",
    "cortical location._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d095a49-8620-4e34-a501-bb08a2b6d152",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Clavagnier, S., Dumoulin, S. O. & Hess, R. F.**\n",
    "#### Is the Cortical Deficit in Amblyopia Due to Reduced Cortical Magnification, Loss of Neural Resolution, or Neural Disorganization? \n",
    "#### _The Journal of Neuroscience_ 35, 14740–14755 (2015).\n",
    "  \n",
    "_To determine cortical magnification factor (CMF), the fMRI data first had\n",
    "to be projected onto a 2D cortical surface (Harvey and Dumoulin, 2011).\n",
    "The distances between each location (mesh vertices) and their neighbor-\n",
    "ing locations could then be computed in millimeters. Local CMF was \n",
    "calculated by dividing the mean cortical distance between the vertices\n",
    "and their neighboring vertices by the mean difference of their preferred\n",
    "pRF locations (in degree of visual angle). CMFs estimated were binned by\n",
    "eccentricity (every 0.25°). The population point image (pPI) was com-\n",
    "puted by multiplying the CMFs and pRF sizes estimated for each cortical\n",
    "location._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea12b2d0-79eb-41be-8964-e0b6aa1f4da4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ROI -> V1 / Hemisphere -> lh: 100%|██████████| 4503/4503 [02:18<00:00, 32.47it/s]\n",
      "ROI -> V1 / Hemisphere -> rh: 100%|██████████| 3890/3890 [01:59<00:00, 32.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# create empty results\n",
    "vert_cm = np.zeros(vert_num)*np.nan\n",
    "\n",
    "for roi in rois:\n",
    "    # find ROI vertex\n",
    "    roi_vert_lh_idx = roi_verts_dict[roi][roi_verts_dict[roi]<lh_vert_num]\n",
    "    roi_vert_rh_idx = roi_verts_dict[roi][roi_verts_dict[roi]>=lh_vert_num]\n",
    "    roi_surf_lh_idx = roi_vert_lh_idx\n",
    "    roi_surf_rh_idx = roi_vert_rh_idx-lh_vert_num\n",
    "\n",
    "    # get mean distance of surounding vertices included in threshold\n",
    "    vert_lh_rsq, vert_lh_size = vert_rsq_data[:lh_vert_num], vert_size_data[:lh_vert_num]\n",
    "    vert_lh_x, vert_lh_y = vert_x_data[:lh_vert_num], vert_y_data[:lh_vert_num]\n",
    "    vert_rh_rsq, vert_rh_size = vert_rsq_data[lh_vert_num:], vert_size_data[lh_vert_num:]\n",
    "    vert_rh_x, vert_rh_y = vert_x_data[lh_vert_num:], vert_y_data[lh_vert_num:]\n",
    "\n",
    "    for hemi in ['lh','rh']:\n",
    "        if hemi == 'lh':\n",
    "            surf = surf_lh\n",
    "            roi_vert_idx, roi_surf_idx = roi_vert_lh_idx, roi_surf_lh_idx\n",
    "            vert_rsq, vert_x, vert_y, vert_size = vert_lh_rsq, vert_lh_x, vert_lh_y, vert_lh_size\n",
    "        elif hemi == 'rh':\n",
    "            surf = surf_rh\n",
    "            roi_vert_idx, roi_surf_idx = roi_vert_rh_idx, roi_surf_rh_idx\n",
    "            vert_rsq, vert_x, vert_y, vert_size = vert_rh_rsq, vert_rh_x, vert_rh_y, vert_rh_size\n",
    "\n",
    "        desc = 'ROI -> {} / Hemisphere -> {}'.format(roi, hemi)\n",
    "        \n",
    "        good_vert_num = roi_surf_idx[vert_rsq[roi_surf_idx]>0].size\n",
    "        with tqdm(total=good_vert_num, desc=desc) as pbar:\n",
    "            \n",
    "            for i, (vert_idx, surf_idx) in enumerate(zip(roi_vert_idx, roi_surf_idx)):\n",
    "                \n",
    "                if vert_rsq[surf_idx] > 0:\n",
    "\n",
    "                    # get geodesic distances (mm)\n",
    "                    try :\n",
    "                        geo_patch = surf.get_geodesic_patch(radius=vert_dist_th, vertex=surf_idx)\n",
    "                    except Exception as e:\n",
    "                        print(\"Vertex #{}: error: {} within {} mm\".format(vert_idx, e, vert_dist_th))\n",
    "                        geo_patch['vertex_mask'] = np.zeros(surf.pts.shape[0]).astype(bool)\n",
    "                        geo_patch['geodesic_distance'] = []\n",
    "                    \n",
    "                    vert_dist_th_idx  = geo_patch['vertex_mask']\n",
    "                    vert_dist_th_dist = np.ones_like(vert_dist_th_idx)*np.nan\n",
    "                    vert_dist_th_dist[vert_dist_th_idx] = geo_patch['geodesic_distance']\n",
    "                    \n",
    "                    # exclude vextex out of roi\n",
    "                    vert_dist_th_not_in_roi_idx = [idx for idx in np.where(vert_dist_th_idx)[0] if idx not in roi_surf_idx]\n",
    "                    vert_dist_th_idx[vert_dist_th_not_in_roi_idx] = False\n",
    "                    vert_dist_th_dist[vert_dist_th_not_in_roi_idx] = np.nan\n",
    "                    \n",
    "                    if np.sum(vert_dist_th_idx) > 0:\n",
    "                    \n",
    "                        # compute average geodesic distance excluding distance to itself (see [1:])\n",
    "                        vert_geo_dist_avg = np.nanmean(vert_dist_th_dist[1:])\n",
    "\n",
    "                        # get prf parameters of vertices in geodesic distance threshold\n",
    "                        vert_ctr_x, vert_ctr_y = vert_x[surf_idx], vert_y[surf_idx]\n",
    "                        vert_dist_th_idx[surf_idx] = False\n",
    "                        vert_srd_x, vert_srd_y = np.nanmean(vert_x[vert_dist_th_idx]), np.nanmean(vert_y[vert_dist_th_idx])\n",
    "\n",
    "                        # compute prf center suround distance (deg)\n",
    "                        vert_prf_dist = np.sqrt((vert_ctr_x - vert_srd_x)**2 + (vert_ctr_y - vert_srd_y)**2)\n",
    "\n",
    "                        # compute cortical magnification in mm/deg (surface distance / pRF positon distance)\n",
    "                        vert_cm[vert_idx] = vert_geo_dist_avg/vert_prf_dist\n",
    "\n",
    "                    pbar.update(1)\n",
    "\n",
    "        pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b22df74-fa3b-47e0-8cdf-a72c242bd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to volume\n",
    "vert_cm_nonan = vert_cm\n",
    "vert_cm_nonan[np.isnan(vert_cm)] = 0\n",
    "vol_cm = mapper.backwards(vert_cm_nonan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bfde6-873a-4363-8900-212b23b1a59b",
   "metadata": {},
   "source": [
    "## Plot on flatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d59d4-1d74-4c62-af33-1d5a4ed9bdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot CM on Vertex2D\n",
    "vert_cm_map = cortex.Vertex2D(dim1=vert_cm, dim2=vert_rsq_data, subject=subject, cmap='hot_alpha', vmin=0, vmax=4, vmin2=0, vmax2=1)\n",
    "cortex.quickshow(vert_cm_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8918cc8b-2e00-4e04-98fe-79d015684a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot CM on VolumeRGB\n",
    "vol_rsq = deriv_mat[...,rsq_idx]\n",
    "param_cm = {'subject': subject, 'xfmname': xfm_name,\n",
    "            'data': vol_cm.T, 'cmap': 'hot', 'alpha': vol_rsq, \n",
    "            'vmin': 0, 'vmax': 4, 'cbar': 'discrete', 'cbar_label': 'pRF CM (mm/deg)',\n",
    "            'cortex_type': 'VolumeRGB', 'description': 'CM',\n",
    "            'curv_brightness': 1, 'curv_contrast': 0.1, 'add_roi': False,\n",
    "            'with_labels': True}\n",
    "\n",
    "volume_cm = draw_cortex(**param_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15609de4-1551-4b18-b486-90729be4828e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 75, 70, 10)\n",
      "(69, 75, 70)\n"
     ]
    }
   ],
   "source": [
    "print(deriv_mat.shape)\n",
    "print(vol_cm.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f81e891-6ab4-457c-ab85-8dd0466401df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save as volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6ff9242-5aa7-4615-b7e6-445b90ed9b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deriv_mat_new = np.zeros((deriv_img.shape[0], deriv_img.shape[1], deriv_img.shape[2], params_num+1))\n",
    "deriv_mat_new[...,:deriv_img.shape[3]] = deriv_mat\n",
    "deriv_mat_new[...,-1] = vol_cm.T\n",
    "\n",
    "deriv_new_img = nb.Nifti1Image(dataobj=deriv_mat_new, affine=deriv_img.affine, header=deriv_img.header)\n",
    "deriv_new_img.to_filename(deriv_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfb675-a154-4eb4-8c4f-d338bb9c81a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot eccentricity effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5e3e8-9114-4de3-a9b0-445b41cb322c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# define roi index (V1 = 0, etc)\n",
    "vert_roi_data = np.zeros(vert_num)\n",
    "for roi_num, roi in enumerate(rois):\n",
    "    vert_roi_data[roi_verts_dict[roi]] = [roi_num]\n",
    "\n",
    "# define dataframe\n",
    "data_mat = np.vstack((vert_roi_data, vert_rsq_data, vert_x_data, vert_y_data, \n",
    "                      vert_size_data, vert_ecc_data, vert_cm)).T\n",
    "\n",
    "df = pd.DataFrame(data=data_mat,\n",
    "                  columns=['roi_num', 'rsq', 'x', 'y', 'size', \n",
    "                           'ecc', 'cm'])\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "roi_colors = px.colors.sequential.Blackbody\n",
    "\n",
    "for roi_num, roi in enumerate(rois):\n",
    "    #get bins\n",
    "    df_roi = df.loc[(df.rsq>=0.3) & (df.roi_num==roi_num)]\n",
    "    ecc_min_bins, ecc_max_bins, ecc_step_bins = 0, 15, 15\n",
    "    bins = np.linspace(ecc_min_bins, ecc_max_bins, ecc_step_bins)\n",
    "    df_bin = df_roi.groupby(pd.cut(df_roi['ecc'], bins=bins))\n",
    "\n",
    "    # Make Figure\n",
    "    fig.add_trace(go.Scatter(x=df_bin.mean().ecc, y=df_bin.mean()['size'], error_y=dict(type='data', array=df_bin.sem()['size']),\n",
    "                             name = roi, legendgroup=roi, showlegend=True, line_color = roi_colors[roi_num]), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=df_bin.mean().ecc, y=df_bin.mean().cm, error_y=dict(type='data', array=df_bin.sem().cm),\n",
    "                             legendgroup=roi, showlegend=False, line_color =  roi_colors[roi_num]), row=1, col=2)\n",
    "\n",
    "fig.update_layout(template= 'simple_white',\n",
    "                  xaxis_title=\"pRF eccentricity (dva)\", xaxis_range = [ecc_min_bins, ecc_max_bins],\n",
    "                  xaxis2_title=\"pRF eccentricity (dva)\", xaxis2_range = [ecc_min_bins, ecc_max_bins],\n",
    "                  yaxis_title=\"pRF size (dva)\", yaxis_range = [0, 10],\n",
    "                  yaxis2_title=\"pCM (mm/dva)\", yaxis2_range = [0, 8])\n",
    "\n",
    "title = \"pRF size, pRF Cortical Magnication  (pCM) vs. pRF eccentricity\"\n",
    "fig.update_layout(height=400, width=800, title_text=title)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24d28a-ee95-4c15-95b7-4a538a76859d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prf_env",
   "language": "python",
   "name": "prf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
